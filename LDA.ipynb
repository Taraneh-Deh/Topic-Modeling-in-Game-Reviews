{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2f622-0f61-4cc9-a98a-7101f9b6d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for data manipulation, NLP, visualization, and clustering\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "\n",
    "# Downloading NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Reading data \n",
    "df = pd.read_excel('')\n",
    "\n",
    "# Initial set of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Adding custom stopwords to the set\n",
    "custom_stopwords = {'done','a', 'for', 'i', 'the', 'expand', 'click', 'contain', 'spoiler', 'it', 'be', 'in', 'one', 'get', 'even', 'year', 'guess', 'see', 'got', 'feel', 'want', 'tell', 'absolute','every','is','some','would','else','in','de','said','us','by','little','decided','bethesda','let','must','done','gam'}\n",
    "\n",
    "# Additional customization of custom stopwords ( These words are repeated for so many times, but they do not provide useful information.) \n",
    "additional_stopwords = {'thousands','los','la','al','to','contains','of','the','ago','much','really','ever','games','played','bosses','go','like','good','say','lot','diego','que','give','review','reviews','people','everyone','never','per','boss','also','many','new','may','back','try','vet','made','make','could','spoilers','first','una','fps','not','find'}\n",
    "custom_stopwords.update(additional_stopwords)\n",
    "\n",
    "# Removing specific custom stopwords\n",
    "custom_stopwords.discard('specific')\n",
    "custom_stopwords.discard('stopword')\n",
    "\n",
    "# Preprocessing the text by removing stopwords\n",
    "#tokenized-review is one of the columns of our the dataset\n",
    "df['tokenized_review'] = df[''].astype(str).apply(\n",
    "    lambda x: [word for word in x.split() if word not in custom_stopwords]\n",
    ")\n",
    "\n",
    "# Topic Modeling class\n",
    "class Topic_Model:\n",
    "    def __init__(self, k=15):\n",
    "        \"\"\"Initialize the topic model with a specified number of topics (k).\"\"\"\n",
    "        self.k = k\n",
    "        self.dictionary = None\n",
    "        self.corpus = None\n",
    "        self.ldamodel = None\n",
    "        self.cluster_model = None\n",
    "        \n",
    "    def prepare_corpus(self, token_lists):\n",
    "        \"\"\"Prepare the dictionary and corpus needed for LDA.\"\"\"\n",
    "        self.dictionary = corpora.Dictionary(token_lists)\n",
    "        self.corpus = [self.dictionary.doc2bow(text) for text in token_lists]\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the LDA model to the prepared corpus and dictionary.\"\"\"\n",
    "        self.ldamodel = LdaModel(self.corpus, num_topics=self.k, id2word=self.dictionary, passes=15)\n",
    "        topic_distributions = self.ldamodel[self.corpus]\n",
    "        features = gensim.matutils.corpus2dense(topic_distributions, num_terms=self.k).T\n",
    "        self.cluster_model = KMeans(n_clusters=self.k, random_state=0)\n",
    "        self.cluster_model.fit(features)\n",
    "\n",
    "    def calculate_coherence(self, tokenized_texts):\n",
    "        \"\"\"Calculate the coherence score of the LDA model.\"\"\"\n",
    "        coherence_model_lda = CoherenceModel(model=self.ldamodel, texts=tokenized_texts, dictionary=self.dictionary, coherence='c_v')\n",
    "        return coherence_model_lda.get_coherence()\n",
    "\n",
    "    def calculate_perplexity(self):\n",
    "        \"\"\"Calculate the perplexity of the LDA model.\"\"\"\n",
    "        return self.ldamodel.log_perplexity(self.corpus)\n",
    "\n",
    "    def calculate_silhouette_score(self):\n",
    "        \"\"\"Calculate silhouette score for the clustering performed by the model.\"\"\"\n",
    "        topic_distributions = self.ldamodel[self.corpus]\n",
    "        features = gensim.matutils.corpus2dense(topic_distributions, num_terms=self.k).T\n",
    "        return silhouette_score(features, self.cluster_model.labels_)\n",
    "\n",
    "    def visualize_topics(self):\n",
    "        \"\"\"Visualize the topics using pyLDAvis.\"\"\"\n",
    "        try:\n",
    "            vis = gensimvis.prepare(self.ldamodel, self.corpus, self.dictionary)\n",
    "            pyLDAvis.save_html(vis, 'lda_visualization.html')\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred during LDA visualization:\")\n",
    "            print(e)\n",
    "            vis = None\n",
    "        return vis\n",
    "\n",
    "    def show_topic_words(self, num_words=15):\n",
    "        \"\"\"Display the top words for each topic.\"\"\"\n",
    "        for i in range(self.k):\n",
    "            words = self.ldamodel.show_topic(i, topn=num_words)\n",
    "            print(f\"Topic {i + 1}: {', '.join([word for word, _ in words])}\")\n",
    "\n",
    "    def visualize_topics_and_word_clouds(self, num_words=30, grid_dims=(3, 5)):\n",
    "        \"\"\"Visualize topics and generate word clouds for each topic.\"\"\"\n",
    "        vis = self.visualize_topics()\n",
    "\n",
    "        topics = self.ldamodel.show_topics(num_topics=self.k, num_words=num_words, formatted=False)\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        gs = gridspec.GridSpec(*grid_dims)\n",
    "        gs.update(wspace=0.5, hspace=0.5)\n",
    "        for i, topic in enumerate(topics):\n",
    "            ax = fig.add_subplot(gs[i])\n",
    "            wordcloud = WordCloud(width=100, height=100, background_color='white').generate_from_frequencies(dict(topic[1]))\n",
    "            ax.imshow(wordcloud, interpolation='bilinear')\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f'Topic {i + 1}')\n",
    "        plt.show()\n",
    "        return vis\n",
    "        \n",
    "    def plot_clusters(self):\n",
    "        \"\"\"Plot the clustering results of the LDA model.\"\"\"\n",
    "        if not hasattr(self, 'cluster_model') or not hasattr(self, 'ldamodel'):\n",
    "            raise ValueError(\"Topic_Model must be fitted first.\")\n",
    "        topic_distributions = self.ldamodel[self.corpus]\n",
    "        features = gensim.matutils.corpus2dense(topic_distributions, num_terms=self.k).T\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=features[:, 0], y=features[:, 1], hue=self.cluster_model.labels_, palette='viridis', legend='full')\n",
    "        plt.title('LDA Clustering Results')\n",
    "        plt.xlabel('Probability of Topic 1')\n",
    "        plt.ylabel('Probability of Topic 2')\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tm = Topic_Model(k=10)\n",
    "    tm.prepare_corpus(df['tokenized_review'].tolist())\n",
    "    tm.fit()\n",
    "    coherence = tm.calculate_coherence(df['tokenized_review'].tolist())\n",
    "    perplexity = tm.calculate_perplexity()\n",
    "    silhouette_avg = tm.calculate_silhouette_score()\n",
    "    print(f\"Coherence Score: {coherence}\")\n",
    "    print(f\"Perplexity: {perplexity}\")\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "    tm.visualize_topics_and_word_clouds()\n",
    "    tm.show_topic_words(num_words=30)\n",
    "    tm.plot_clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c13a6-0ad7-49d2-af3d-3109b323e7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
