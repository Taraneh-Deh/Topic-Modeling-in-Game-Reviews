{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c336e8b-6a88-495b-b6c2-c11c51c0396d",
   "metadata": {},
   "source": [
    "**Extracting reviews from the Metacritic website:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9abf9-6776-47f5-9d78-9668239109cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import requests  # Making HTTP requests\n",
    "from bs4 import BeautifulSoup  # Parsing HTML and XML documents\n",
    "from fake_useragent import UserAgent  # Generating fake user agents to mimic browser behavior\n",
    "import pandas as pd  \n",
    "import time \n",
    "\n",
    "# Setting the URL of the webpage from which we're scraping data\n",
    "url = ''\n",
    "# Generating a random user-agent header for our HTTP request\n",
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.chrome}\n",
    "\n",
    "# Sending a GET request to the specified URL with the headers\n",
    "response = requests.get(url, headers=headers)\n",
    "# Parsing the response content with BeautifulSoup using 'html.parser'\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# Extracting the text of the last page number from the page navigation\n",
    "last_page = soup.find('li', class_='page last_page').get_text().strip()\n",
    "\n",
    "# Determining the actual last page number if pagination includes an ellipsis ('…')\n",
    "if '…' in last_page:\n",
    "    last_page = int(last_page.split('…')[-1])\n",
    "else:\n",
    "    last_page = int(last_page)\n",
    "\n",
    "# Initializing a list to store data collected from each page\n",
    "data = []\n",
    "\n",
    "# Iterating over each page URL by updating the page query parameter\n",
    "for page in range(0, last_page * 10, 10):\n",
    "    # Constructing the URL for the current page by appending the page number\n",
    "    page_url = f'{url}?page={page}'\n",
    "    # Making a GET request to fetch the page content\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "    # Parsing the fetched page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Finding all div elements that contain user reviews\n",
    "    user_reviews = soup.find_all('div', class_='review_body')\n",
    "    # Finding all div elements that contain user ratings\n",
    "    user_rates = soup.find_all('div', class_='review_grade')\n",
    "    # Finding all div elements that contain posting dates\n",
    "    user_dates = soup.find_all('div', class_='review_critic')\n",
    "\n",
    "    # Extracting text data from each user review and appending it to our data list\n",
    "    for i in range(len(user_reviews)):\n",
    "        review = user_reviews[i].get_text().strip()\n",
    "        rate = user_rates[i].get_text().strip()\n",
    "        date = user_dates[i].get_text().strip()\n",
    "        data.append({'User Review': review, 'User Rate': rate, 'Post Date': date})\n",
    "\n",
    "    # Pausing the script for 1 second to reduce load on the server\n",
    "    time.sleep(1)\n",
    "\n",
    "# Converting the list of data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Saving the DataFrame to an Excel\n",
    "df.to_excel('dataset.xlsx', index=False)\n",
    "# Printing the total number of comments saved as a confirmation\n",
    "print(f'{len(data)} comments saved to dataset.xls')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba59ea1-a7c7-46ce-91a7-ab71851160e1",
   "metadata": {},
   "source": [
    "**Translating Non-English reviews to English:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54dd24-7bc8-49c3-b16e-f1a6fde175bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd  \n",
    "from langdetect import detect  # Detecting the language of texts\n",
    "from googletrans import Translator  # Translating text using Google Translate API\n",
    "\n",
    "# Loading dataset\n",
    "df = pd.read_excel('')\n",
    "\n",
    "# Creating a Translator object specifying Google's translate service URL\n",
    "translator = Translator(service_urls=['translate.google.com'])\n",
    "# Setting a minimum length threshold for texts to translate\n",
    "length_threshold = 3\n",
    "\n",
    "# Setting a default language in case detection fails\n",
    "default_language = 'en'\n",
    "\n",
    "# Iterating over each row in the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    review = row['User Review']  # Extracting the user review text\n",
    "\n",
    "    # Checking if the review is a string and not just white space\n",
    "    if isinstance(review, str):\n",
    "        # Skipping translation for reviews that are too short or non-textual\n",
    "        if len(review) < length_threshold or not review.strip():\n",
    "            continue\n",
    "        \n",
    "        # Attempting to detect the language of the review\n",
    "        try:\n",
    "            detected_language = detect(review)\n",
    "        except:\n",
    "            # Using the default language if detection fails\n",
    "            detected_language = default_language\n",
    "        \n",
    "        # Translating the review to English if it's not already in English\n",
    "        if detected_language != 'en':\n",
    "            try:\n",
    "                # Translating the review and updating the DataFrame with the translated text\n",
    "                translated_review = translator.translate(review, dest='en').text\n",
    "                print(f\"Translated review: {translated_review}\")\n",
    "                df.at[i, 'User Review'] = translated_review\n",
    "            except Exception as e:\n",
    "                # Handling translation errors and logging them\n",
    "                print(f\"Translation error occurred for review: {review}\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "# Saving the updated DataFrame with translated reviews to an Excel file\n",
    "df.to_excel('translated_dataset.xlsx', index=False)\n",
    "# Confirming that the dataset has been saved\n",
    "print('Translated dataset saved to translated_dataset.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
