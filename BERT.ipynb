{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc6bc6-5479-458e-bd44-5e5b27dfb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_excel('')\n",
    "df = df.dropna(subset=[''])\n",
    "\n",
    "# Loading pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizing and encoding the dataset with attention mask\n",
    "tokenized_texts = [tokenizer(text, truncation=True, max_length=512, padding='max_length', return_tensors='pt') for text in df['']]\n",
    "input_ids = torch.cat([item['input_ids'] for item in tokenized_texts])\n",
    "attention_masks = torch.cat([item['attention_mask'] for item in tokenized_texts])\n",
    "\n",
    "# Creating DataLoader\n",
    "batch_size = 32\n",
    "data = TensorDataset(input_ids, attention_masks)\n",
    "data_loader = DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "# Extracting embeddings\n",
    "embeddings = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_ids, attention_mask = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "        embeddings.append(batch_embeddings)\n",
    "embeddings = torch.cat(embeddings, dim=0).numpy()\n",
    "\n",
    "# Applying KMeans clustering\n",
    "num_clusters = 10  \n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Calculating silhouette score\n",
    "silhouette_avg = silhouette_score(embeddings, clusters)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Adding clusters to DataFrame\n",
    "df['bert_cluster'] = clusters\n",
    "\n",
    "# Using t-SNE to reduce dimensionality for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Adding t-SNE results to the DataFrame\n",
    "df['tsne_x'], df['tsne_y'] = reduced_embeddings[:, 0], reduced_embeddings[:, 1]\n",
    "\n",
    "# Plotting with t-SNE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='tsne_x', y='tsne_y', hue='bert_cluster', data=df, palette='viridis', legend='full')\n",
    "plt.title('BERT Clustering with t-SNE')\n",
    "plt.xlabel('t-SNE dimension 1')\n",
    "plt.ylabel('t-SNE dimension 2')\n",
    "plt.show()\n",
    "\n",
    "# Defining custom stopwords\n",
    "custom_stopwords = {'done', 'a', 'for', 'i', 'the', 'expand', 'click', 'contain', 'spoiler', 'it', 'be', 'in', 'one', 'get', 'even', 'year', 'guess', 'see', 'got', 'feel', 'want', 'tell', 'absolute', 'every', 'is', 'some', 'would', 'else', 'de', 'said', 'us', 'by', 'little', 'decided', 'bethesda', 'let', 'must', 'gam', 'thousands', 'los', 'la', 'al', 'to', 'contains', 'of', 'ago', 'much', 'really', 'ever', 'games', 'played', 'bosses', 'go', 'like', 'good', 'say', 'lot', 'diego', 'que', 'give', 'review', 'reviews', 'people', 'everyone', 'never', 'per', 'boss', 'also', 'many', 'new', 'may', 'back', 'try', 'vet', 'made', 'make', 'could', 'spoilers', 'first', 'una', 'fps', 'not', 'find'}\n",
    "additional_stopwords = {'thousands', 'los', 'la', 'al', 'to', 'contains', 'of', 'the', 'ago', 'much', 'really', 'ever', 'games', 'played', 'bosses', 'go', 'like', 'good', 'say', 'lot', 'diego', 'que', 'give', 'review', 'reviews', 'people', 'everyone', 'never', 'per', 'boss', 'also', 'many', 'new', 'may', 'back', 'try', 'vet', 'made', 'make', 'could', 'spoilers', 'first', 'una', 'fps', 'not', 'find'}\n",
    "custom_stopwords.update(additional_stopwords)\n",
    "\n",
    "# Initializing TF-IDF Vectorizer with custom stopwords\n",
    "vectorizer = TfidfVectorizer(stop_words=list(custom_stopwords), max_features=10000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df[''])\n",
    "\n",
    "# Converting to array and getting feature names\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Function to get top tfidf words for each cluster\n",
    "def get_top_tfidf_words_per_cluster(tfidf_array, feature_names, num_clusters, top_n=30):  \n",
    "    top_words = {}\n",
    "    for cluster_id in range(num_clusters):\n",
    "        indices = np.where(df['bert_cluster'] == cluster_id)[0]\n",
    "        mean_tfidf = np.mean(tfidf_array[indices], axis=0)\n",
    "        top_indices = mean_tfidf.argsort()[-top_n:][::-1]\n",
    "        top_words[cluster_id] = [(feature_names[i], mean_tfidf[i]) for i in top_indices]\n",
    "    return top_words\n",
    "\n",
    "top_tfidf_words = get_top_tfidf_words_per_cluster(tfidf_array, feature_names, num_clusters)\n",
    "\n",
    "# Plotting Word Clouds for each BERT-based cluster\n",
    "def plot_tfidf_word_clouds(top_words, num_clusters):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = gridspec.GridSpec(3, 4)\n",
    "    gs.update(wspace=0.5, hspace=0.5)\n",
    "\n",
    "    for cluster_id in range(num_clusters):\n",
    "        words_scores = {word: score for word, score in top_words[cluster_id]}\n",
    "        ax = fig.add_subplot(gs[cluster_id])\n",
    "        wordcloud = WordCloud(width=200, height=200, background_color='white').generate_from_frequencies(words_scores)\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Cluster {cluster_id + 1}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_tfidf_word_clouds(top_tfidf_words, num_clusters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
