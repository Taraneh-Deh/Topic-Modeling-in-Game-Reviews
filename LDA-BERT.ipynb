{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7fbc0-dc29-4517-8f65-a5ba641f2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim import corpora, models, matutils\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Downloading NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Defining Topic Modeling Class\n",
    "class Topic_Model:\n",
    "    def __init__(self, k=15, method='LDA_BERT', gamma=15, token_lists=None):\n",
    "        self.k = k\n",
    "        self.dictionary = None\n",
    "        self.corpus = None\n",
    "        self.cluster_model = None\n",
    "        self.ldamodel = None\n",
    "        self.vec = {}\n",
    "        self.gamma = gamma  # Relative importance of LDA\n",
    "        self.method = method\n",
    "        self.id = method + '_' + datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        self.token_lists = token_lists\n",
    "        \n",
    "    def vectorize(self, sentences, token_lists, method=None):\n",
    "        if method is None:\n",
    "            method = self.method\n",
    "\n",
    "        if method == 'LDA':\n",
    "            if not self.ldamodel:\n",
    "                self.dictionary = corpora.Dictionary(token_lists)\n",
    "                self.corpus = [self.dictionary.doc2bow(text) for text in token_lists]\n",
    "                self.ldamodel = models.ldamodel.LdaModel(self.corpus, num_topics=self.k, id2word=self.dictionary, passes=20)\n",
    "            vec = matutils.corpus2dense(self.ldamodel[self.corpus], num_terms=self.k).T\n",
    "            return vec\n",
    "\n",
    "        elif method == 'BERT':\n",
    "            model = SentenceTransformer('bert-base-nli-max-tokens')\n",
    "            vec = np.array(model.encode(sentences, show_progress_bar=True))\n",
    "            return vec\n",
    "\n",
    "        elif method == 'LDA_BERT':\n",
    "            vec_lda = self.vectorize(sentences, token_lists, method='LDA')\n",
    "            vec_bert = self.vectorize(sentences, None, method='BERT')\n",
    "            vec_ldabert = np.c_[vec_lda * self.gamma, vec_bert]\n",
    "            return vec_ldabert\n",
    "\n",
    "    def calculate_coherence(self, token_lists):\n",
    "        if not self.ldamodel or not self.corpus:\n",
    "            raise ValueError(\"LDA model and corpus must be trained before calculating coherence.\")\n",
    "        coherence_model_lda = CoherenceModel(model=self.ldamodel, texts=token_lists, dictionary=self.dictionary, coherence='c_v')\n",
    "        return coherence_model_lda.get_coherence()\n",
    "\n",
    "    def calculate_perplexity(self):\n",
    "        if not self.ldamodel or not self.corpus:\n",
    "            raise ValueError(\"LDA model and corpus must be trained before calculating perplexity.\")\n",
    "        return self.ldamodel.log_perplexity(self.corpus)\n",
    "\n",
    "    def fitting(self, sentences, token_lists, method=None):\n",
    "        if method is None:\n",
    "            method = self.method\n",
    "        vec = self.vectorize(sentences, token_lists, method)\n",
    "        self.vec[method] = vec\n",
    "    \n",
    "        if method in ['LDA_BERT', 'BERT']:\n",
    "            # Clustering for BERT or LDA_BERT\n",
    "            self.cluster_model = KMeans(n_clusters=self.k, random_state=0)\n",
    "            self.cluster_model.fit(vec)\n",
    "            silhouette_avg = silhouette_score(vec, self.cluster_model.labels_)\n",
    "            print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "        \n",
    "        elif method == 'LDA': \n",
    "            pass\n",
    "\n",
    "\n",
    "    def visualizing_topics(self):\n",
    "        try:\n",
    "            if not self.ldamodel:\n",
    "                raise ValueError(\"LDA model must be fitted first.\")\n",
    "    \n",
    "            if self.method == 'LDA':\n",
    "                # For LDA: Visualize using pyLDAvis and save to HTML\n",
    "                vis = gensimvis.prepare(self.ldamodel, self.corpus, self.dictionary)\n",
    "                pyLDAvis.save_html(vis, 'lda_visualization2.html')\n",
    "                print(\"LDA visualization saved as lda_visualization2.html\")\n",
    "    \n",
    "            elif self.method in ['BERT', 'LDA_BERT']:\n",
    "                # Ensuring the vectors exist\n",
    "                if self.method not in self.vec:\n",
    "                    raise ValueError(f\"Vectors for method {self.method} not found. Ensure that you've fitted the model with '{self.method}' method.\")\n",
    "    \n",
    "                # t-SNE for dimensionality reduction, assuming 'self.vec' holds our method-specific vectors\n",
    "                tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "                tsne_vectors = tsne_model.fit_transform(self.vec[self.method])\n",
    "    \n",
    "                # Adjusting labels to start from 1 instead of 0\n",
    "                hue_labels = [label + 1 for label in self.cluster_model.labels_]\n",
    "    \n",
    "                # Plotting\n",
    "                plt.figure(figsize=(16, 10))\n",
    "                sns.scatterplot(\n",
    "                    x=tsne_vectors[:, 0], y=tsne_vectors[:, 1],\n",
    "                    hue=hue_labels,  # Use adjusted labels\n",
    "                    palette=sns.color_palette(\"hls\", self.k),\n",
    "                    legend=\"full\",\n",
    "                    alpha=0.7\n",
    "                )\n",
    "                plt.title(f\"t-SNE visualization of {self.method} clusters\")\n",
    "                plt.show()\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during topic visualization: {e}\")\n",
    "\n",
    "\n",
    "    \n",
    "    def getting_top_words_for_each_cluster(self, num_words=10):\n",
    "        if not self.ldamodel or not self.cluster_model:\n",
    "            raise ValueError(\"LDA model and cluster model must be fitted first.\")\n",
    "        \n",
    "        # Ensuring num_words matches the number of clusters, self.k\n",
    "        num_words = self.k  # Set num_words to the number of clusters\n",
    "        \n",
    "        top_words_per_cluster = {}\n",
    "        for cluster_id in range(self.k):\n",
    "            cluster_indices = np.where(self.cluster_model.labels_ == cluster_id)[0]\n",
    "            cluster_sentences = [self.token_lists[i] for i in cluster_indices]\n",
    "            cluster_tokenized_words = [word for sentence in cluster_sentences for word in sentence]\n",
    "            word_counts = nltk.FreqDist(cluster_tokenized_words)\n",
    "            top_words = [word for word, _ in word_counts.most_common(num_words)]\n",
    "            top_words_per_cluster[cluster_id] = top_words\n",
    "        \n",
    "        return top_words_per_cluster\n",
    "\n",
    "\n",
    "\n",
    "    def generating_word_clouds(self, num_words=50):\n",
    "    # Ensuring that the LDA model has been trained\n",
    "        if not self.ldamodel:\n",
    "            raise ValueError(\"LDA model must be trained before generating word clouds.\")\n",
    "\n",
    "        for t in range(self.ldamodel.num_topics):\n",
    "            # Extracting the words and their probabilities for the topic\n",
    "            topic_words_probs = self.ldamodel.show_topic(t, topn=num_words)\n",
    "            # Creating a dictionary with word-probability pairs\n",
    "            topic_words_probs_dict = {word: prob for word, prob in topic_words_probs}\n",
    "\n",
    "            # Generating the word cloud\n",
    "            wordcloud = WordCloud(background_color='white').generate_from_frequencies(topic_words_probs_dict)\n",
    "\n",
    "            \n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Word Cloud for Topic #{t}')\n",
    "            plt.show()\n",
    "        \n",
    "    def showing_topic(self, topic_index, num_words=15):\n",
    "        if not self.ldamodel:\n",
    "            raise ValueError(\"LDA model must be fitted first.\")\n",
    "        if topic_index < 0 or topic_index >= self.k:\n",
    "            raise ValueError(f\"Invalid topic index. Please choose a value between 0 and {self.k - 1}\")\n",
    "        topic_words = self.ldamodel.show_topic(topic_index, topn=num_words)\n",
    "        print(f\"Topic {topic_index}:\")\n",
    "        for word, prob in topic_words:\n",
    "            print(f\"  {word}: {prob:.4f}\")\n",
    "\n",
    "def showing_all_topics(self, num_words=15):\n",
    "    if not self.ldamodel:\n",
    "        raise ValueError(\"LDA model must be fitted first.\")\n",
    "    for topic_index in range(self.k):\n",
    "        # Adjusting the topic index for display\n",
    "        adjusted_topic_index = topic_index + 1\n",
    "        self.show_topic(adjusted_topic_index, num_words)\n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  \n",
    "    file_path = ''\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df.fillna('')\n",
    "# Additional customization of custom stopwords ( These words are repeated for so many times, but they do not provide useful information.) \n",
    "    custom_stopwords = {'done','a', 'for', 'i', 'the', 'expand', 'click', 'contain', 'spoiler', 'it', 'be', 'in', 'one', 'get', 'even', 'year', 'guess', 'see', 'got', 'feel', 'want', 'tell', 'absolute','every','is','some','would','else','in','de','said','us','by','little','decided','bethesda','let','must','done','gam','thousands','los','la','al','to','contains','of','the','ago','much','really','ever','games','played','bosses','go','like','good','say','lot','diego','que','give','review','reviews','people','everyone','never','per','boss','also','many','new','may','back','try','vet','made','make','could','spoilers','first','una','fps','not','find'}\n",
    "    local_stopwords = stop_words.union(custom_stopwords)\n",
    "    df['tokenized_review'] = df[''].apply(lambda x: [word for word in x.split() if word not in local_stopwords] if isinstance(x, str) else [])\n",
    "\n",
    "    token_lists = df['tokenized_review'].tolist()\n",
    "    tm = Topic_Model(k=10, method='LDA_BERT', gamma=20, token_lists=token_lists)\n",
    "\n",
    "    # Fitting the model\n",
    "    sentences = df[''].tolist()\n",
    "    tm.fitting(sentences, token_lists)\n",
    "\n",
    "    # Depending on the method, performing the respective tasks\n",
    "    if tm.method == 'LDA':\n",
    "        # For LDA: Calculating coherence and perplexity\n",
    "        coherence = tm.calculate_coherence(token_lists)\n",
    "        print(f\"Coherence Score: {coherence}\")\n",
    "        \n",
    "        perplexity = tm.calculate_perplexity()\n",
    "        print(f\"Perplexity: {perplexity}\")\n",
    "\n",
    "        # Generating word clouds and visualizing topics\n",
    "        tm.generating_word_clouds(num_words=50)\n",
    "        tm.visualizing_topics()\n",
    "        tm.showing_all_topics()\n",
    "\n",
    "    elif tm.method == 'BERT':\n",
    "        # For BERT: Getting top words for each cluster, and visualizing topics\n",
    "        top_words_per_cluster = tm.getting_top_words_for_each_cluster()\n",
    "        print(top_words_per_cluster)\n",
    "\n",
    "        tm.visualizing_topics()\n",
    "\n",
    "    elif tm.method == 'LDA_BERT':\n",
    " \n",
    "        coherence = tm.calculate_coherence(token_lists)\n",
    "        print(f\"Coherence Score: {coherence}\")\n",
    "        \n",
    "        perplexity = tm.calculate_perplexity()\n",
    "        print(f\"Perplexity: {perplexity}\")\n",
    "\n",
    "        top_words_per_cluster = tm.getting_top_words_for_each_cluster()\n",
    "        print(top_words_per_cluster)\n",
    "\n",
    "        tm.generating_word_clouds(num_words=50)\n",
    "        tm.visualizing_topics()\n",
    "        tm.showing_all_topics()\n",
    "\n",
    "    else:\n",
    "        print(f\"Method {tm.method} not recognized.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
